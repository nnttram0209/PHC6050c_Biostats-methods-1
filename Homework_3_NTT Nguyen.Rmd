---
title: "Homework_3_NTTNguyen"
author: "Ngoc Thuy Tram (Tram) Nguyen"
date: "2024-09-16"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1
```{r}
library(faraway)
```
Fit a model with gamble as the response and the other variables as predictors.
```{r}
lmod1a <- lm(gamble ~ ., data=teengamb)
```

###a
95% and 99%CI for the parameter associated with **income**.
```{r}
CI_95pct <- confint(lmod1a, "income", level=0.95)
CI_99pct <- confint(lmod1a, "income", level=0.99)
CI_95pct
CI_99pct
```
As 95% and 99%CIs do not include 0, we can deduce that p-value of **income** coefficient is lower than the levels of significance (i.e., in this question is 0.05 and 0.01, respectively) => p-value of **income** <0.01

###b
```{r}
confint(lmod1a, c("status", "verbal"), level=0.90)
require(ellipse)
plot(ellipse(lmod1a, c(3,5), level=0.90), type="l", ylim=c(-9,5))
points(0, 0, pch=19)
abline(v=confint(lmod1a, "status", level=0.90), lty=2)
abline(h=confint(lmod1a, "verbal", level=0.90), lty=2)
```
The null hypothesis H0: beta(verbal)=beta(status)=0 at 10% level of significance.
As the origin lies within the 90% joint confidence region, we fail to reject the null hypothesis above.

###c
Execute the permutation test corresponding to the t-test for **sex** in `lmod1a`
```{r}
t_sex <- summary(lmod1a)$coef[2,3]
tstats <- numeric(5000)
set.seed(200)
for (i in 1:5000) {  #Do 5000 permutations
     lmod <- lm(gamble ~ sample(sex) + status + income + verbal, data=teengamb)
     tstats[i] <- summary(lmod)$coef[2,3]
}
mean(abs(tstats) > abs(t_sex))
```

###d
In `lmod1a` model, only **income** is significant at the 1% level, so I fit the new model names `lmod1b` with only **income** as predictor.
```{r}
lmod1b <- lm(gamble ~ income, data=teengamb)
```

Compare `lmod1b` with `lmod1a` (F-test)
```{r}
anova(lmod1b, lmod1a)
```
As p-value >0.01, we fail to reject the null hypothesis H0: beta(sex)=beta(status)=beta(verbal)=0. Thus, `lmod1b` is preferred at the 1% level.


## Question 2
###a
Fit a regression model with **lpsa** as the response and the other variables as predictors (model `lmod2a`)
```{r}
lmod2a <- lm (lpsa ~ ., data=prostate)
summary(lmod2a)
```
From the table above, we see that **lcavol**, **lweight**, **svi** are statistically significant at the 1% level (i.e. p-value <0.01).

###b 
Fit new model `lmod2b`, which is the same model as `lmod2a` but with **lcavol**, **lbph**, **lweight**, and **lcp** are on their original scale.
```{r}
lmod2b <- lm(lpsa ~ exp(lcavol) + exp(lbph) + exp(lweight) + exp(lcp) +
                  age + svi + gleason + pgg45, data=prostate)
summary(lmod2b)
```
The table above shows that **exp(lcavol)**, **exp(lbph)**, **svi** are the predictors that are statistically significant at the 5% level for the model `lmod2b`.

###c
`lmod2a` and `lmod2b` are not nested models so we can't use F-test to compare these two models. We can compare adjusted R-squared of two models: the one with higher R-squared will be the better fit model.
```{r}
summary(lmod2a)$adj.r.squared*100
summary(lmod2b)$adj.r.squared*100
```

R-squared values of `lmod2a` and `lmod2b` are 62.34% and 53.78%, respectively. Thus `lmod2a` is the better fit model. 

###d
```{r}
summary(lmod2a)
```
Coefficient (beta) of **lcavol** in `lmod2a` is 0.587022, so if **lcavol** increased by 0.01 for model `lmod2a`, the response **lpsa** would increase by 0.01*beta(lcavol), which approximates 0.0059.
```{r}
beta_lcavol <- summary(lmod2a)$coef[2,1]
0.01*beta_lcavol
```

###e
An additive increase of 0.01 on **lcavol** (the (natural) log scale) corresponds to a change of `exp(0.01)` **times** on the original scale. This corresponds to a percentage change of `(exp(0.01)-1)* 100(%)`, which equals 1.005%.
```{r}
pct_change <- (exp(0.01) - 1)*100
pct_change
```

## Question 3
F = [ESS/(p-1)] / [RSS/(n-p)] 
  = [ESS/RSS] * [(n-p)/(p-1)] 
  = [(TSS-RSS)/RSS] * [(n-p)/(p-1)]
  = [(TSS/RSS) - 1] * [(n-p)/(p-1)]
  = [(1/(1-R.square)) - 1] * [(n-p)/(p-1)]
  = [R.square / (1-R.square)] * [(n-p)/(p-1)]
  

R-square and F-test help to assess how well the model explains the variance in the response and whether the predictors are statistically significant.